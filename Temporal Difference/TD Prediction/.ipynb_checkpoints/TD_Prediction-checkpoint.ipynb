{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6nxA7Wif7_Ix"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "BBCjdRXC8bGd",
    "outputId": "da2ea81b-639a-41e4-f730-a4c5cdf468b0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nMaking a Randomwalk Environment with 2n+1 states. \\n\\n0l . . . 0 0 0 0 0 0 0 0 S 0 0 0 0 0 0 0 0 . . . 0r\\n\\n0l and 0r denote the terminal states. \\n\\nAction Space : \\n\\n0 (Left) \\n1 (Right)\\n\\nRewards Setting : \\n\\n-1 : Agent goes to 0l\\n+1 : Agent goes to 0r\\n0 : Intermediary States\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Making a Randomwalk Environment with 2n+1 states.\n",
    "\n",
    "0l . . . 0 0 0 0 0 0 0 0 S 0 0 0 0 0 0 0 0 . . . 0r\n",
    "\n",
    "0l and 0r denote the terminal states.\n",
    "\n",
    "Action Space :\n",
    "\n",
    "-1 (Left)\n",
    "+1 (Right)\n",
    "\n",
    "Rewards Setting :\n",
    "\n",
    "-1 : Agent goes to 0l\n",
    "+1 : Agent goes to 0r\n",
    "0 : Intermediary States\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "fC9k_-YPDURc"
   },
   "outputs": [],
   "source": [
    "def initialize_env(states=19):\n",
    "  STATES = states\n",
    "  value_list = np.zeros(STATES)\n",
    "  state_check = np.zeros(STATES)\n",
    "  rewards = np.zeros(STATES)\n",
    "  rewards[0] = -1\n",
    "  rewards[STATES-1] = 1\n",
    "  start_pos = (STATES+1)/2 -1\n",
    "  action_space = [-1, 1]\n",
    "  return value_list, state_check, int(start_pos), rewards, action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "r1d7qoktMnhz"
   },
   "outputs": [],
   "source": [
    "def action(action_space = a):\n",
    "  return random.choice(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "MfaqsNfHDjB6"
   },
   "outputs": [],
   "source": [
    "#TD Update v[ith] = v[ith] + alpha * (reward + gamma * v[ith+1] - v[ith]) for non terminal\n",
    "#TD Update v[ith] = v[ith] + alpha * (reward - [vith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "WgWPyL_OFWAO"
   },
   "outputs": [],
   "source": [
    "v, s, pos, r, a = initialize_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a_xdF3hFgay",
    "outputId": "d3d2a107-e076-454b-ead3-bfcf37ca4270"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAniKlcbFhX6",
    "outputId": "d634e910-e0f0-4992-d22a-9eea437a97ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvr6OHozFif4",
    "outputId": "ae314818-604e-4a02-9258-a7f48702759a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHklGkT3Slam",
    "outputId": "ce0a7820-4134-4268-be45-32c6913f05c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "ZWdyPkWqChfI"
   },
   "outputs": [],
   "source": [
    "def isTerminal (current_state, STATES):\n",
    "  if current_state ==0 or current_state == STATES -1:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "def step (current_state, action, rewards, STATES) :\n",
    "  action = action\n",
    "  next_state = current_state + action\n",
    "  reward = rewards[next_state]\n",
    "  isT = isTerminal (current_state, STATES)\n",
    "  return next_state, reward\n",
    "\n",
    "def calc_TD_nonT(current_state, next_state, reward, alpha, gamma, value_list):\n",
    "  value_list[current_state] += alpha * (reward + gamma * (value_list[next_state]) - value_list[current_state])\n",
    "  return value_list\n",
    "\n",
    "def calc_TD_T(current_state, reward, alpha, gamma, value_list):\n",
    "  value_list[current_state] += alpha * (reward - value_list[current_state])\n",
    "  return value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "gmlCO5_rM_0Y"
   },
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "gamma = 0.10\n",
    "isT = False\n",
    "steps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPJvGZK9QDAR",
    "outputId": "7e3852ca-f440-43f1-9c04-796acf243836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 12\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 12\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 5\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 5\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 11\n",
      "The reward obtained is 0.0\n",
      "The next state is 10\n",
      "The reward obtained is 0.0\n",
      "The next state is 9\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 8\n",
      "The reward obtained is 0.0\n",
      "The next state is 7\n",
      "The reward obtained is 0.0\n",
      "The next state is 6\n",
      "The reward obtained is 0.0\n",
      "The next state is 5\n",
      "The reward obtained is 0.0\n",
      "The next state is 4\n",
      "The reward obtained is 0.0\n",
      "The next state is 3\n",
      "The reward obtained is 0.0\n",
      "The next state is 2\n",
      "The reward obtained is 0.0\n",
      "The next state is 1\n",
      "The reward obtained is 0.0\n",
      "The next state is 2\n",
      "The reward obtained is 0.0\n",
      "The next state is 3\n",
      "The reward obtained is 0.0\n",
      "The next state is 2\n",
      "The reward obtained is 0.0\n",
      "The next state is 1\n",
      "The reward obtained is 0.0\n",
      "This is the terminal state - 0\n",
      "The reward is -1.0\n",
      "The episode has ended here\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "  while isT != True:\n",
    "    next_state, reward= step(pos, action(), r, 19)\n",
    "    isT = isTerminal(next_state, 19)\n",
    "    if isT == True:\n",
    "      print(f\"This is the terminal state - {next_state}\")\n",
    "      print(f\"The reward is {reward}\")\n",
    "      v = calc_TD_T (pos, reward, alpha, gamma, v)\n",
    "      print (\"The episode has ended here\")\n",
    "      break\n",
    "    else:\n",
    "      print(f\"The next state is {next_state}\")\n",
    "      print(f\"The reward obtained is {reward}\")\n",
    "      v= calc_TD_nonT(pos, next_state, reward, alpha, gamma, v)\n",
    "      pos = next_state\n",
    "  return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggb0IwRjXM8O",
    "outputId": "d5f5eafd-d48a-4a76-dc0a-2e0643a5108e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   , -0.001,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2pLXGZUbnrA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
